#!/bin/bash
# CC-G 3.1 - CommonCrawl Global Uploader (2.5â€¯Gbps ä¼˜åŒ–)
# âœ¨ å…³é”®æ”¹åŠ¨
#   1. ç”¨ rclone size --json å³æ—¶éªŒè¯å®¹é‡ï¼Œè§£å†³ Google Drive about å»¶è¿Ÿé—®é¢˜ã€‚
#   2. æ–°å¢ verify_batch() å¸¦é‡è¯•çª—å£ï¼›è¿ç»­éªŒè¯å¤±è´¥ 3 æ¬¡æ‰è§†ä¸ºæ— è¿›å±•ã€‚
#   3. å®æ—¶ç»Ÿè®¡å¹¶è¾“å‡ºæ¯æ‰¹æ¬¡å¹³å‡é€Ÿåº¦ä¸å®é™…æ–°å¢å®¹é‡ã€‚
#   4. ä¿æŒåŸæœ‰ä½é€Ÿåˆ‡æ¢é€»è¾‘ã€‚

set -euo pipefail

###################### åŸºæœ¬é…ç½® ######################
WARC_LIST_URL="https://data.commoncrawl.org/crawl-data/CC-MAIN-2025-30/warc.paths.gz"
DEST_PATH="/dx"
MAX_TRANSFER="700G"

# 2.5â€¯Gbps å¸¦å®½ä¼˜åŒ–
THREADS=16
CHUNK_SIZE="256M"
BUFFER_SIZE="2G"
MULTI_THREAD_STREAMS=8
CHECKERS=32
LOW_SPEED_MB=50
LOW_SPEED_SECONDS=45

TMP_DIR="/tmp/warc_uploader"
LOG_DIR="./logs"
mkdir -p "$TMP_DIR" "$LOG_DIR"

export LANG=zh_CN.UTF-8
export LC_ALL=zh_CN.UTF-8

###################### å·¥å…·å‡½æ•° ######################
# è¿›ç¨‹æ¸…ç†
cleanup() {
  local mon_pid=${1:-}
  [[ -n "$mon_pid" && $(kill -0 "$mon_pid" 2>/dev/null || echo 0) ]] && {
    kill -TERM "$mon_pid" 2>/dev/null || true; sleep 1; kill -KILL "$mon_pid" 2>/dev/null || true;
  }
  pkill -f "rclone copyurl.*$REMOTE:" 2>/dev/null || true
}

# æ‰¹æ¬¡å®¹é‡éªŒè¯ï¼ˆä½¿ç”¨ rclone sizeï¼‰
MAX_VERIFY_ATTEMPTS=6  # å…±å°è¯• 6Ã—30â€¯s â‰ˆ 3â€¯min
VERIFY_INTERVAL=30
verify_batch() {
  local last_bytes=$1
  local new_bytes=0
  local attempts=0
  while (( attempts < MAX_VERIFY_ATTEMPTS )); do
    new_bytes=$(rclone size "$REMOTE:$DEST_PATH" --json 2>/dev/null | jq -r '.bytes // 0')
    if (( new_bytes > last_bytes )); then
      echo "$new_bytes"  # è¿”å›æœ€æ–°å·²ç”¨å­—èŠ‚æ•°
      return 0
    fi
    attempts=$((attempts+1))
    sleep $VERIFY_INTERVAL
  done
  echo "$last_bytes"  # æœªå˜åŒ–
  return 1
}

###################### ç”¨æˆ·äº¤äº’ ######################
cat <<'EOF'
 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•     â–ˆâ–ˆâ•”â•â•â•â•â•     â•šâ•â•â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘     â•šâ•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘     â•šâ•â•â•â–ˆâ–ˆâ•—
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
 â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•      â•šâ•â•â•â•â•â•     â•šâ•â•â•â•â•â•
ğŸŒ CommonCrawl Global Uploader v3.1
ğŸ“Š ä¼˜åŒ–ç‰ˆæœ¬ - 2.5â€¯Gbps å¸¦å®½
EOF

echo "ğŸ”§ THREADS=$THREADS | CHUNK=$CHUNK_SIZE | BUFFER=$BUFFER_SIZE"

read -rp "â° å¾ªç¯é—´éš”å°æ—¶æ•° (0=ä»…æ‰§è¡Œä¸€æ¬¡): " REPEAT_INTERVAL_HOURS
ALL_REMOTES=$(rclone listremotes | sed 's/:$//')
echo -e "\nğŸŸ¢ å¯ç”¨å­˜å‚¨èŠ‚ç‚¹:\n$(echo "$ALL_REMOTES" | sed 's/^/   â”œâ”€ /')"
read -rp "ğŸ¯ é€‰æ‹©è¦ä½¿ç”¨çš„èŠ‚ç‚¹ (ç©ºæ ¼åˆ†éš”): " -a SELECTED_REMOTES
read -rp "ğŸ“ èµ·å§‹æ–‡ä»¶è¡Œå· (é»˜è®¤1): " START_LINE
START_LINE=${START_LINE:-1}

###################### ä¸‹è½½æ–‡ä»¶åˆ—è¡¨ ######################
WARC_FILE="$TMP_DIR/warc.paths"
echo -n "ğŸ“¥ è·å–æ–‡ä»¶åˆ—è¡¨... "
curl -sL "$WARC_LIST_URL" | gunzip -c > "$WARC_FILE" && echo "å®Œæˆ" || { echo "å¤±è´¥"; exit 1; }
TOTAL_LINES=$(wc -l < "$WARC_FILE")
echo "æ€»æ–‡ä»¶æ•°: $TOTAL_LINES"

###################### ä¸»å¾ªç¯ ######################
while :; do
  echo -e "\n========== æ–°ä¸€è½®ä¸Šä¼  $(date '+%F %T') =========="
  for REMOTE in "${SELECTED_REMOTES[@]}"; do
    echo -e "\nâ”Œâ”€ ğŸš€ èŠ‚ç‚¹: $REMOTE"
    PROGRESS_FILE="$TMP_DIR/${REMOTE}.progress"
    USED_FILE="$TMP_DIR/${REMOTE}.used"
    LOGFILE="$LOG_DIR/${REMOTE}_$(date +%F_%H-%M-%S).log"
    SPEED_LOG="$TMP_DIR/${REMOTE}_speed.log"
    FLAG_FILE="$TMP_DIR/${REMOTE}_slow.flag"

    [[ -f "$PROGRESS_FILE" ]] || echo "$START_LINE" > "$PROGRESS_FILE"
    CURRENT_LINE=$(<"$PROGRESS_FILE")

    # åˆå§‹å®¹é‡
    LAST_USED=$(rclone size "$REMOTE:$DEST_PATH" --json | jq -r '.bytes // 0')
    echo "$LAST_USED" > "$USED_FILE"

    NO_PROGRESS=0

    while (( CURRENT_LINE <= TOTAL_LINES )); do
      BATCH_END=$(( CURRENT_LINE + THREADS - 1 ))
      (( BATCH_END > TOTAL_LINES )) && BATCH_END=$TOTAL_LINES

      echo -e "\nâ”œâ”€ ğŸš€ æ‰¹æ¬¡ $CURRENT_LINE-$BATCH_END å…± $((BATCH_END-CURRENT_LINE+1)) æ–‡ä»¶"

      # å‡†å¤‡æ‰¹æ¬¡åˆ—è¡¨
      BATCH_LIST="$TMP_DIR/${REMOTE}_batch_${CURRENT_LINE}.txt"
      BATCH_URLS="$TMP_DIR/${REMOTE}_urls_${CURRENT_LINE}.txt"
      sed -n "${CURRENT_LINE},${BATCH_END}p" "$WARC_FILE" > "$BATCH_LIST"
      sed "s|^|https://data.commoncrawl.org/|" "$BATCH_LIST" > "$BATCH_URLS"

      # é‡ç½®ç›‘æ§æ ‡è®°
      echo 0 > "$FLAG_FILE"; : > "$SPEED_LOG"

      # é€Ÿåº¦ç›‘æ§åå°è¿›ç¨‹
      monitor_speed() {
        local slow=0 checks=0 tot=0
        while [[ $(<"$FLAG_FILE") == 0 ]]; do
          sleep 5; checks=$((checks+1)); tot=0
          # å–æœ€è¿‘ç»Ÿè®¡
          local lines=$(tail -n 20 "$SPEED_LOG" | grep -o '[0-9.]\+MiB/s' || true)
          for s in $lines; do tot=$(awk -v t="$tot" -v v="${s%MiB/s}" 'BEGIN{print t+v}'); done
          local avg=0; [[ $checks -gt 0 && $lines ]] && avg=$(awk -v t="$tot" -v n="$(echo "$lines" | wc -w)" 'BEGIN{printf "%.1f", t/n}')
          (( checks % 2 == 0 )) && printf "\râ”œâ”€ ğŸ“ˆ å³æ—¶é€Ÿåº¦ %.1f MiB/s " "$avg"
          # å¯åŠ¨å®½é™ & ä½é€Ÿæ£€æµ‹
          [[ $checks -le 6 ]] && continue  # å‰ 30â€¯s ä¸æ£€æµ‹
          (( ${avg%.*} < LOW_SPEED_MB )) && slow=$((slow+5)) || slow=0
          if (( slow >= LOW_SPEED_SECONDS )); then
            echo -e "\nâ”œâ”€ ğŸŒ ä½é€Ÿè§¦å‘: $avg MiB/s < $LOW_SPEED_MB"
            echo 1 > "$FLAG_FILE"; return; fi
          # å®‰å…¨ä¸Šé™
          (( checks*5 >= 600 )) && { echo -e "\nâ”œâ”€ â° è¶…æ—¶åˆ‡æ¢"; echo 1 > "$FLAG_FILE"; return; }
        done
      }
      monitor_speed & MON_PID=$!

      # å¯åŠ¨ä¸Šä¼ å­è¿›ç¨‹
      UPLOAD_PIDS=(); idx=0
      while IFS= read -r url && (( idx < THREADS )); do
        filename=$(basename "$url")
        rclone copyurl "$url" "$REMOTE:$DEST_PATH" \
          --auto-filename \
          --drive-chunk-size "$CHUNK_SIZE" \
          --buffer-size "$BUFFER_SIZE" \
          --multi-thread-streams "$MULTI_THREAD_STREAMS" \
          --checkers 4 \
          --disable-http2 \
          --max-transfer "$MAX_TRANSFER" \
          --timeout 30m \
          --retries 2 \
          --low-level-retries 5 \
          --stats 5s \
          --stats-one-line \
          >> "$SPEED_LOG" 2>> "$LOGFILE" &
        UPLOAD_PIDS+=("$!"); idx=$((idx+1))
        echo "â”œâ”€ ğŸ”— å¯åŠ¨çº¿ç¨‹ $idx: ${filename:0:40}..."
      done < "$BATCH_URLS"
      echo "â”œâ”€ âš¡ å…± ${#UPLOAD_PIDS[@]} çº¿ç¨‹"

      # ç­‰å¾…ä¸Šä¼ å®Œæˆæˆ–ä½é€Ÿè§¦å‘
      while :; do
        [[ $(<"$FLAG_FILE") == 1 ]] && {
          echo "â”œâ”€ ğŸ›‘ ä½é€Ÿä¸­æ­¢æ‰¹æ¬¡"; for p in "${UPLOAD_PIDS[@]}"; do kill -TERM "$p" 2>/dev/null || true; done; break; }
        alive=0; for p in "${UPLOAD_PIDS[@]}"; do kill -0 "$p" 2>/dev/null && alive=$((alive+1)); done
        (( alive == 0 )) && break; sleep 3
      done

      # æ¸…ç†
      cleanup "$MON_PID"

      # ç»Ÿè®¡å¹³å‡é€Ÿåº¦
      AVG_SPEED=$(grep -o '[0-9.]\+MiB/s' "$SPEED_LOG" | awk -F'MiB/s' '{sum+=$1} END{ if(NR) printf "%.1f", sum/NR; else print 0}')

      # å®¹é‡éªŒè¯
      NEW_USED=$(verify_batch "$LAST_USED") && verify_ok=$? || verify_ok=$?
      size_diff=$(( (NEW_USED - LAST_USED)/1024/1024 ))
      if (( verify_ok == 0 )); then
        echo "â”œâ”€ âœ… æ‰¹æ¬¡å®Œæˆ | æ–°å¢ ${size_diff}â€¯MB | å¹³å‡é€Ÿåº¦ ${AVG_SPEED}â€¯MiB/s"
        LAST_USED=$NEW_USED; NO_PROGRESS=0
      else
        echo "â”œâ”€ âš ï¸  æ— å®¹é‡å˜åŒ– (å°è¯• ${NO_PROGRESS}/3) | å¹³å‡é€Ÿåº¦ ${AVG_SPEED}â€¯MiB/s"
        NO_PROGRESS=$((NO_PROGRESS+1))
      fi

      # è¿ç»­å¤±è´¥åˆ‡èŠ‚ç‚¹
      if (( NO_PROGRESS >= 3 )); then
        echo "â””â”€ ğŸš« è¿ç»­ 3 æ¬¡æ— è¿›å±•ï¼Œåˆ‡æ¢èŠ‚ç‚¹"
        break
      fi

      # è®°å½•è¿›åº¦
      CURRENT_LINE=$(( BATCH_END + 1 ))
      echo "$CURRENT_LINE" > "$PROGRESS_FILE"
      # æ¸…ç†ä¸´æ—¶
      rm -f "$BATCH_LIST" "$BATCH_URLS" "$SPEED_LOG"
    done
    rm -f "$FLAG_FILE" "$SPEED_LOG"
    echo "â””â”€ âœ… èŠ‚ç‚¹ $REMOTE å®Œæˆæœ¬è½®"
  done

  (( REPEAT_INTERVAL_HOURS == 0 )) && { echo "ğŸ‰ å…¨éƒ¨ä»»åŠ¡å®Œæˆ"; exit 0; }
  echo "ğŸ’¤ ä¼‘çœ  ${REPEAT_INTERVAL_HOURS}h åç»§ç»­..."; sleep $(( REPEAT_INTERVAL_HOURS*3600 ))
done
